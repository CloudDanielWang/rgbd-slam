// OpenCV 库
#include <opencv2/opencv.hpp>
#include<vector> 

// C++ 标准库
#include <stdio.h>  
#include <iostream> 

// PCL 库
#include <pcl/io/pcd_io.h>
#include <pcl/point_types.h>




using namespace cv;
using namespace std;
using namespace pcl;

// 定义点云类型
typedef PointXYZRGBA PointT;
typedef PointCloud<PointT> pointcloud; 



//********************矩阵函数定义***********************//
void m_mult3x3_3x1(float a[3][3],float b[3],float r[3])
{
  for(int i=0;i<3;i++)
  {  
     r[i]=0;
     for(int j=0;j<3;j++)   
        r[i]+=a[i][j]*b[j];
  }
}

void m_add3x3(float a[3][3],float b[3][3],float r[3][3])
{
  for (int i=0;i<3;i++)
     for(int j=0;j<3;j++)
          r[i][j]=a[i][j]+b[i][j];
}

void m_mult3xPM_L_POINTS_PM_L_POINTSx3(float a[3][1],float b[1][3],float r[3][3])
{
 
  for(int i=0;i<3;i++)
  {
  	for(int j=0;j<3;j++)
  	{     
            r[i][j]=0;
  	   for(int p=0;p<1;p++)   
           r[i][j]+=a[i][p]*b[p][j];
  	}
  }
}

//********************矩阵函数定义***********************//


/************************************************************************/
/*                                                 ！！！！主函数！！！！                                                     */
/************************************************************************/

int main()
{
	VideoCapture capture(CV_CAP_OPENNI);    //设置视频的来源为OPENNI设备，即Kinect

while(1)
{
	double mindepth, maxdepth;
	const int minDistance = 400; // mm
        
	float base = (float)capture.get( CAP_OPENNI_DEPTH_GENERATOR_BASELINE ); // mm
	float F = (float)capture.get( CAP_OPENNI_DEPTH_GENERATOR_FOCAL_LENGTH ); // pixels 
	float maxDisparity = base * F / minDistance;
	
	vector<DMatch> best_Matche_point;
	
    Mat depthMap1,depthMap2;				//存放深度图像
    Mat depthshow1,depthshow2; 				//存放转化位视差的深度图像
    Mat img1,img2;		//临时存放连续两帧的图像
    Mat cloudMap_now,cloudMap_ref;	//存放三维坐标图像
    

    capture.set( CV_CAP_OPENNI_IMAGE_GENERATOR_OUTPUT_MODE, CV_CAP_OPENNI_VGA_30HZ );		//设置Kinect彩色摄像头工作模式


/////////////////////////第一帧//////////////////////////////////   
	capture.grab();       			 //从Kinect捕获一次图像
              
	capture.retrieve( img1, CV_CAP_OPENNI_BGR_IMAGE );   //取彩色摄像头信息放与bgrImage1矩阵中
	
	namedWindow("图像截取界面", WINDOW_AUTOSIZE);
	imshow("图像截取界面",img1);		//显示第一帧图像
	
	capture.retrieve( depthMap1, CV_CAP_OPENNI_DEPTH_MAP );    //取深度摄像头的信息放入depthMap矩阵中，openCV的openNI接口中，已经将
													// 深度图像进行的视角的矫正，使得图像与彩色摄像头位置重合
													//见cap_openni2.cpp videoio_c.h 
	// imshow("深度图像未转化",depthMap);											
	depthMap1.convertTo( depthshow1, CV_32FC1, 0.05f);		//将获得的深度图像转变为disparity in pixels格式，且为32位。事实上由深度图像变为了灰度图像
	//imshow( "深度图像", depthshow1 );						//显示转化后的深度图像
	
	
	capture.retrieve( cloudMap_ref,  CV_CAP_OPENNI_POINT_CLOUD_MAP );		//获取第一帧的三维坐标


	//保存点云数据于文件中	
	//saveData("cloudMap_ref.txt",cloudMap_ref, 3);
///////////////////第一帧结束//////////////////////

	cout<<"按任意键截取第二帧图像\n";	
        waitKey(0);		//等待按键

//////////////////第二帧/////////////////////////
	capture.grab();				//抓取第二帧图像
	
	capture.retrieve( img2, CV_CAP_OPENNI_BGR_IMAGE );
	imshow("图像截取界面",img2);

	capture.retrieve( depthMap2, CV_CAP_OPENNI_DEPTH_MAP ); 
	depthMap2.convertTo( depthshow2, CV_32FC1, 0.05f);
	capture.retrieve( cloudMap_now,  CV_CAP_OPENNI_POINT_CLOUD_MAP );		//获取第二帧的三维坐标
	//保存点云数据于文件中	
	//saveData("cloudMap_now.txt",cloudMap_now, 3);
	
///////////////////第二帧结束//////////////////////


//*****************************开始对进行点云运算********************************************/
//参考自http://www.cnblogs.com/gaoxiang12/p/4652478.html，修改了三维坐标来源
    // 点云变量
    // 使用智能指针，创建一个空点云。这种指针用完会自动释放。
    pointcloud::Ptr cloud ( new pointcloud );
    // 遍历深度图
    for (int m = 0; m < depthMap1.rows; m++)
        for (int n=0; n < depthMap1.cols; n++)
        {
            PointT p;

            // 计算这个点的空间坐标
		p.x =double(cloudMap_now.at<Vec3f>(m,n)[0]);
		p.y =double(cloudMap_now.at<Vec3f>(m,n)[1]);
		p.z =double(cloudMap_now.at<Vec3f>(m,n)[2]);
            
            // 从rgb图像中获取它的颜色
            // rgb是三通道的BGR格式图，所以按下面的顺序获取颜色
            p.b = img1.ptr<uchar>(m)[n*3];
            p.g = img1.ptr<uchar>(m)[n*3+1];
            p.r = img1.ptr<uchar>(m)[n*3+2];

            // 把p加入到点云中
            cloud->points.push_back( p );
        }
    // 设置并保存点云
    cloud->height = 1;
    cloud->width = cloud->points.size();
    cout<<"point cloud size = "<<cloud->points.size()<<endl;
    cloud->is_dense = false;
    pcl::io::savePCDFile( "../data/pointcloud.pcd", *cloud );
    // 清除数据并退出
    cloud->points.clear();
    cout<<"Point cloud saved."<<endl;
//*****************************点云保存成功**********************************************/



 cout<<"按任意键开始匹配\n";	
waitKey(0);		//等待按键开始匹配

//*****************************开始对两帧图像进行ORB特征************************************************/
//ORB特征点匹配    来源于openCV sample 中的ORB匹配示例源码
//本程序中采用了ORB算法的BruteForce-Hamming(2)实现方法，其余方法给予了注释，需要时去除注释即可。

    vector<String> typeDesc;
    vector<String> typeAlgoMatch;

    typeDesc.push_back("ORB");      // see http://docs.opencv.org/trunk/de/dbf/classcv_1_1BRISK.html

    typeAlgoMatch.push_back("BruteForce-Hamming(2)");   //经初步测试，该算法得出的匹配点较少而且准确

    vector<double> desMethCmp;
    Ptr<Feature2D> b;

    // Descriptor loop
   	vector<String>::iterator itDesc;

    	itDesc = typeDesc.begin();
        Ptr<DescriptorMatcher> descriptorMatcher;
        // Match between img1 and img2
        vector<DMatch> matches;				//将匹配点放于此，数据为keypoint中的索引
        // keypoint  for img1 and img2
        vector<KeyPoint> keyImg1, keyImg2;		//存放匹配点的XYZ坐标
        // Descriptor for img1 and img2
        Mat descImg1, descImg2;
        vector<String>::iterator itMatcher = typeAlgoMatch.end();

        b = ORB::create();


            // We can detect keypoint with detect method
            b->detect(img1, keyImg1, Mat());
            // and compute their descriptors with method  compute
            b->compute(img1, keyImg1, descImg1);
            // or detect and compute descriptors in one step
            b->detectAndCompute(img2, Mat(),keyImg2, descImg2,false);
            // Match method loop
            itMatcher = typeAlgoMatch.begin();

                descriptorMatcher = DescriptorMatcher::create(*itMatcher);
                descriptorMatcher->match(descImg1, descImg2, matches, Mat());
                    // Keep best matches only to have a nice drawing.
                    // We sort distance between descriptor matches
                    Mat index;
                    int nbMatch=int(matches.size());
                    Mat tab(nbMatch, 1, CV_32F);
                    for (int i = 0; i<nbMatch; i++)
                    {
                        tab.at<float>(i, 0) = matches[i].distance;
                    }
                    sortIdx(tab, index, SORT_EVERY_COLUMN + SORT_ASCENDING);
                    vector<DMatch> bestMatches;								//将最佳匹配点存放于bestMatches中
                    for (int i = 0; i<100; i++)
                    {
                        bestMatches.push_back(matches[index.at<int>(i, 0)]);
                    }
                    Mat result;
                    drawMatches(img1, keyImg1, img2, keyImg2, bestMatches, result);
                   // namedWindow("ORB匹配结果", WINDOW_AUTOSIZE);
                    imshow("ORB匹配结果", result);
		    cout<<"ORB匹配完成\n";	
                    // Saved result could be wrong due to bug 4308
                    //FileStorage fs("ORB匹配数据.yml", FileStorage::WRITE);				
                    //fs<<"Matches"<<bestMatches;								//将最佳匹配点的数据输出至yml文件（暂不需要）
                    //vector<DMatch>::iterator it;
                    //cout<<"**********Match results**********\n";								//输出匹配点结果于终端
                    //cout << "Index \tIndex \tdistance\n";
                    //cout << "in img1\tin img2\n";
                    // Use to compute distance between keyPoint matches and to evaluate match algorithm
/*                    double cumSumDist2=0;
                    for (it = bestMatches.begin(); it != bestMatches.end(); ++it)
                    {
                        cout << it->queryIdx << "\t" <<  it->trainIdx << "\t"  <<  it->distance << "\n";
                        Point2d p=keyImg1[it->queryIdx].pt-keyImg2[it->trainIdx].pt;
                        cumSumDist2=p.x*p.x+p.y*p.y;		//计算的是关键点之间的距离
                    }
                    desMethCmp.push_back(cumSumDist2);

                   

    //匹配结果的终端显示
    int i=0;
    cout << "以下是算法匹配点的距离和 \n\t";

    for (vector<String>::iterator itMatcher = typeAlgoMatch.begin(); itMatcher != typeAlgoMatch.end(); ++itMatcher)
    {
        cout<<*itMatcher<<"\t";
    }
    cout << "\n";
    for (itDesc = typeDesc.begin(); itDesc != typeDesc.end(); ++itDesc)
    {
        cout << *itDesc << "\t";
        for (vector<String>::iterator itMatcher = typeAlgoMatch.begin(); itMatcher != typeAlgoMatch.end(); ++itMatcher, ++i)
        {
            cout << desMethCmp[i]<<"\t";
        }
        cout<<"\n";
    }
*/
//***************************************匹配结束************************************************/

                    waitKey(0);
//***************************************将匹配点的坐标找到***************************************/
//将xyz数据分别存在数组中

        int sum_points=bestMatches.size();
	float  good_matchpoints_ref[sum_points][3];
	float  good_matchpoints_now[sum_points][3];   

        int  sum_good_matchpoints=0;
//  	for  (int i=0;i<sum_points;i++)
 //   {

    //keypoint 中的x对应列,y对应行  匹配对中两个点坐标有一个为0就舍去
/*
       if((cloudMap_now.at<Vec3f>(now_x,now_y)[2]*1000.0f>20)&&(cloudMap_ref.at<Vec3f>(ref_x,ref_y)[2]*1000.0f>20))
         {
           	  good_matchpoints_now[sum_good_matchpoints][0]=cloudMap_now.at<Vec3f>(now_x,now_y)[0]*1000.0f;
                  good_matchpoints_ref[sum_good_matchpoints][0]=cloudMap_ref.at<Vec3f>(ref_x,ref_y)[0]*1000.0f ;
                  good_matchpoints_now[sum_good_matchpoints][1]=cloudMap_now.at<Vec3f>(now_x,now_y)[1]*1000.0f ;
                  good_matchpoints_ref[sum_good_matchpoints][1]=cloudMap_ref.at<Vec3f>(ref_x,ref_y)[1]*1000.0f ;
                  good_matchpoints_now[sum_good_matchpoints][2]=cloudMap_now.at<Vec3f>(now_x,now_y)[2]*1000.0f ;
                  good_matchpoints_ref[sum_good_matchpoints][2]=cloudMap_ref.at<Vec3f>(ref_x,ref_y)[2]*1000.0f;

      //     printf("now:%f  ref:%f \n ",good_matchpoints_now[sum_good_matchpoints][0],good_matchpoints_ref[sum_good_matchpoints][0]); 
      //     printf("now:%f  ref:%f \n ",good_matchpoints_now[sum_good_matchpoints][1],good_matchpoints_ref[sum_good_matchpoints][1]); 
      //     printf("now:%f  ref:%f \n ",good_matchpoints_now[sum_good_matchpoints][2],good_matchpoints_ref[sum_good_matchpoints][2]); 
          	 sum_good_matchpoints++;
         }

    }
printf("sum:%d \n",sum_good_matchpoints);			//输出总的满足要求（坐标值不为零）的匹配点数目
//***************************************找寻结束************************************************/

//***************************************iPnP求解位姿变换************************************************/
	vector <Point3f> pts_obj;
	vector <Point2f> pts_img;
	
     // 相机内参
struct CAMERA_INTRINSIC_PARAMETERS 
{ 
    double cx, cy, fx, fy, scale;
};
	CAMERA_INTRINSIC_PARAMETERS C;
	C.cx = 325.5;
	C.cy = 253.5;
	C.fx = 518.0;
	C.fy = 519.0;
	C.scale = 1000.0;

	double camera_matrix_data[3][3] = 
	{
		{C.fx, 0, C.cx},
		{0, C.fy, C.cy},
		{0, 0, 1}
	};
	
	for  (int i=0;i<sum_points;i++)
       {	

		int now =bestMatches[i].queryIdx;  
		int ref =bestMatches[i].trainIdx;       
		int now_y=keyImg1[now].pt.x;
		int now_x=keyImg1[now].pt.y;
		int ref_y=keyImg2[ref].pt.x;
		int ref_x=keyImg2[ref].pt.y;

		if((cloudMap_now.at<Vec3f>(now_x,now_y)[2]==0.0)||(cloudMap_ref.at<Vec3f>(ref_x,ref_y)[2]==0.0)) continue;

		pts_img.push_back( Point2f( keyImg2[ref].pt ) );		


		Point3f p3d (((now_y-C.cx*cloudMap_now.at<Vec3f>(now_x,now_y)[2])/C.fx,((now_x-C.cy)*cloudMap_now.at<Vec3f>(now_x,now_y)[2])/C.fy,cloudMap_now.at<Vec3f>(now_x,now_y)[2]);

		pts_obj.push_back(p3d);
		
	}

	Mat cameraMatrix( 3, 3, CV_64F, camera_matrix_data );
	Mat rvec, tvec, inliers;
	solvePnPRansac( pts_obj, pts_img, cameraMatrix, cv::Mat(), rvec, tvec, false, SOLVEPNP_P3P );

	rvec=rvec*180.0/3.1415925;
	tvec=tvec*1000.0;
	//cout<<"inliers: "<<inliers.rows<<endl;
	cout<<"R="<<rvec<<endl;
	cout<<"t="<<tvec<<endl;

//***************************************PnP求解位姿变换结束************************************************/





//***************************************icp迭代求解的过程************************************************/
/*      //1.计算点云中心点 以及 点云平移

     Point3f center_now, center_ref;
     for  (int k=0;k<sum_good_matchpoints;k++)
     {
        center_now.x +=  good_matchpoints_now[k][0];
        center_now.y +=  good_matchpoints_now[k][1];
        center_now.z +=  good_matchpoints_now[k][2];

        center_ref.x +=  good_matchpoints_ref[k][0];
        center_ref.y +=  good_matchpoints_ref[k][1];
        center_ref.z +=  good_matchpoints_ref[k][2];
     }
     center_now.x = center_now.x/sum_good_matchpoints;
     center_now.y = center_now.y/sum_good_matchpoints;
     center_now.z = center_now.z/sum_good_matchpoints;

     center_ref.x = center_ref.x/sum_good_matchpoints;
     center_ref.y = center_ref.y/sum_good_matchpoints;
     center_ref.z = center_ref.z/sum_good_matchpoints;

    float  trans_good_matchpoints_ref[sum_good_matchpoints][3];
    float  trans_good_matchpoints_now[sum_good_matchpoints][3]; 

     for  (int k=0;k<sum_good_matchpoints;k++)
     {
        trans_good_matchpoints_now[k][0] = good_matchpoints_now[k][0]-center_now.x;
        trans_good_matchpoints_now[k][1] = good_matchpoints_now[k][1]-center_now.y;
        trans_good_matchpoints_now[k][2] = good_matchpoints_now[k][2]-center_now.z;

        trans_good_matchpoints_ref[k][0] = good_matchpoints_ref[k][0]-center_ref.x;
        trans_good_matchpoints_ref[k][1] = good_matchpoints_ref[k][1]-center_ref.y;
        trans_good_matchpoints_ref[k][2] = good_matchpoints_ref[k][2]-center_ref.z;

	  //printf("now:%f  ref:%f \n ",trans_good_matchpoints_now[k][0], trans_good_matchpoints_ref[k][0]); 
          //printf("now:%f  ref:%f \n ",trans_good_matchpoints_now[k][1],trans_good_matchpoints_ref[k][1]); 
          //printf("now:%f  ref:%f \n ",trans_good_matchpoints_now[k][2],trans_good_matchpoints_ref[k][2]); 
     }

      //2. 求解正定矩阵B的最大特征值及其特征向量  使用CvMat数据
     float sum_pq[3][3];

     for(int k=0;k<sum_good_matchpoints;k++)
     {
          float pqmul[3][3];          
          float p[3][1]={trans_good_matchpoints_now[k][0],trans_good_matchpoints_now[k][1],trans_good_matchpoints_now[k][2]};
          float q[1][3]={trans_good_matchpoints_ref[k][0],trans_good_matchpoints_ref[k][1],trans_good_matchpoints_ref[k][2]}; 
          m_mult3xPM_L_POINTS_PM_L_POINTSx3(p,q,pqmul);
          m_add3x3(sum_pq,pqmul,sum_pq) ;       
     }
     for(int i=0;i<3;i++)
     {
        for(int j=0;j<3;j++)
        {
            sum_pq[i][j]=sum_pq[i][j]/sum_good_matchpoints;
        }
     } 
     float tr=sum_pq[0][0]+sum_pq[1][1]+sum_pq[2][2];
     float aa[3][3];
     for(int i=0;i<3;i++)
     {
        for(int j=0;j<3;j++)
        {
            aa[i][j]=sum_pq[i][j]+sum_pq[j][i];
            if(i==j)
            aa[i][j]=sum_pq[i][j]+sum_pq[j][i]-tr;
            
        }
     } 
     float bb[3][3];
        for(int i=0;i<3;i++)
     {
        for(int j=0;j<3;j++)
        {
            bb[i][j]=sum_pq[i][j]-sum_pq[j][i];
        }
     } 
     Mat B=Mat::zeros(4, 4,CV_32FC1);
     B.at<float>(0,0)=tr;
     B.at<float>(0,1)=bb[2][3];
     B.at<float>(0,2)=bb[3][1];
     B.at<float>(0,3)=bb[1][2];
     B.at<float>(1,0)=bb[2][3];
     B.at<float>(2,0)=bb[3][1];
     B.at<float>(3,0)=bb[1][2];
        for(int i=0;i<3;i++)
     {
        for(int j=0;j<3;j++)
        {
            B.at<float>(i+1,j+1)=aa[i][j];
        }
     }

      CvMat Cv_B=B;
      CvMat* P_Cv_B=&Cv_B;        //定义指针初始化取变量的地址
      CvMat* eig=cvCreateMat(4,1,CV_32FC1);
      CvMat* eig_vector=cvCreateMat(4,4,CV_32FC1);
      cvEigenVV(P_Cv_B,eig_vector,eig);    //函数的形参是指针,实参必须是地址,可以是类型指针,也可以是类型数据地址
      float max_eig, max_eig_vector[4];
      max_eig=cvGetReal2D(eig,0,0);
      for(int i=0;i<4;i++)
      {
         max_eig_vector[i]=cvGetReal2D(eig_vector,0,i);
      }

       //3.求解旋转矩阵R以及平移矩阵T
      float R[3][3],q[4];
      for(int i=0;i<4;i++)
      {
         q[i]=max_eig_vector[i];
	//printf("%f   ",q[i]);
      }
      R[0][0] = q[0]*q[0] + q[1]*q[1] - q[2]*q[2] - q[3]*q[3];  
      R[0][1] = 2.0 * (q[1]*q[2] - q[0]*q[3]);  
      R[0][2] = 2.0 * (q[1]*q[3] + q[0]*q[2]);  
      R[1][0] = 2.0 * (q[1]*q[2] + q[0]*q[3]);  
      R[1][1] = q[0]*q[0] - q[1]*q[1] + q[2]*q[2] - q[3]*q[3];  
      R[1][2] = 2.0 * (q[2]*q[3] - q[0]*q[1]);  
      R[2][0] = 2.0 * (q[1]*q[3] - q[0]*q[2]);  
      R[2][1] = 2.0 * (q[2]*q[3] + q[0]*q[1]);  
      R[2][2] = q[0]*q[0] - q[1]*q[1] - q[2]*q[2] + q[3]*q[3];  
/*
          for(int i=0;i<3;i++)
     {
        for(int j=0;j<3;j++)
        {
            cout<<R[i][j]<<endl;
        }
     }  
*/

      //平移矩阵是计算 每个点的平移并求和再平均后得到的

/*      float mat_center_now[3]={center_now.x,center_now.y,center_now.z};
      float Rmat_center_now[3]={center_now.x,center_now.y,center_now.z};

      float mat_center_ref[3]={center_ref.x,center_ref.y,center_ref.z};
      float sum_T[3]={0,0,0} , T[3]={0,0,0};

	m_mult3x3_3x1(R,mat_center_now,Rmat_center_now);

     for(int i=0;i<3;i++)
        {
             T[i]=mat_center_ref[i]-Rmat_center_now[i];
             //cout<<T[i]<<endl;
        }
	cout << "X \t"<<T[0]<<endl;
	cout << "Y \t"<<T[1]<<endl;
	cout << "Z \t"<<T[2]<<endl;

//***************************************icp迭代结束************************************************/

    cout << "一轮匹配结束,按键以关闭此轮窗口\n\t";

	waitKey(0);

	destroyWindow("图像截取界面");		
	destroyWindow("ORB匹配结果");

	cout << "敲击回车键以继续\n\t";
	while(getchar()!='\n');
}

    return 0;
}
